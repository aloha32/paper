# paper
自用paper总结
# 2024.10.23
上传了paper文件包含8篇文章，两个坑待填，KAN和Hiera
# 2024.10.24
[Hiera](https://github.com/facebookresearch/hiera)论文看了好久，最终卡在图4，发现Hiera与MAE的关系机器紧密，[MAE](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper)是何凯明CVPR2022的作品(稍微看了一眼，好像没给代码，难道只是一种训练方法？)，明天先读一下MAE补充一下背景知识吧，ViT也有点忘了，明天小看一下。
# 2024.10.26
![MAE论文图1-**架构**](https://github.com/aloha32/paper/blob/main/MAE-P1.jpg)
初次看根本看不懂，什么mask，什么token，什么decoder，根本搞不懂。问了GPT恍然大悟。
```
图1展示了**MAE（Masked Autoencoder）架构**的流程，主要分为三个部分：输入、编码器-解码器、输出目标。下面详细解释图中各部分的流程：

1. **输入（input）**：
   - 输入图像被划分成不重叠的小块（patches），例如16x16像素的图像块。
   - 在预训练阶段，这些图像块中的大部分（通常为75%）被随机掩盖（图中用灰色方块表示）。这样，仅有少部分的图像块是可见的（图中为彩色部分）。

2. **编码器（encoder）**：
   - 编码器只作用于**可见的图像块**，即没有被掩码的部分。与传统自编码器不同，MAE的编码器并不接收掩码标记作为输入，而是直接对可见图像块进行编码。
   - 编码器的任务是从可见的部分学习出图像的潜在表示（latent representation），这些表示用一系列蓝色方块表示。

3. **解码器（decoder）**：
   - 在编码完成之后，**掩码标记（mask tokens）**被引入，并与编码后的可见图像块组合在一起。每个掩码标记用灰色方块表示，代表被掩盖的图像块。
   - 解码器处理这组完整的编码块（包括编码后的可见块和掩码标记），并通过生成缺失图像块来**重建完整的图像**。解码器的计算量较小，通常是轻量级的。
   - 解码器的输出为一组重建的图像块（红色方块），这些块代表了模型对被掩盖区域的预测。

4. **目标（target）**：
   - 最终，解码器重建的图像与原始输入图像的像素级别进行对比（只对被掩盖的区域进行损失计算）。模型通过最小化重建误差来优化自我监督学习任务。
   - 在预训练结束后，解码器被丢弃，编码器则用于**下游任务**（如图像分类或目标检测），此时输入为完整的、没有掩盖的图像。

**总结**：
图1展示了MAE如何通过随机掩盖大部分图像块，并训练编码器-解码器架构来重建图像。这种方法有助于模型学习全局特征，并能够在图像自监督学习中实现良好的性能。
```
# 2024.10.27
![MAE论文实现细节]（https://github.com/aloha32/paper/blob/main/MAE-SI.jpg）
翻译晦涩难懂，经过GPT导师的指导恍然大悟
```
在这一段中，作者描述了MAE（Masked Autoencoder）模型在预训练中的实现细节，具体说明了如何简化掩码的处理。以下是逐步解释：

1. **生成Token**：
   - 首先，模型会对每个输入的图像块（patch）生成一个**token**，这个过程通过**线性投影**和**位置嵌入**完成。这样每个图像块就有一个唯一的表示，带有位置信息。

2. **随机打乱和掩码选择**：
   - 接下来，将生成的token列表**随机打乱**（randomly shuffle），然后按照设定的掩码比例将列表的最后一部分移除。例如，如果掩码比例是75%，则移除掉列表的最后75%的token。
   - 这个过程相当于对图像块进行**无替换的采样**，即每个token被移除后不会重新加入列表。

3. **编码器的输入**：
   - 经过上述步骤，剩下的token构成了一个小的子集，这些token会被输入到**编码器**中进行处理，而被移除的部分相当于被掩盖了。

4. **添加掩码标记并恢复顺序**：
   - 在编码完成之后，将一组**掩码标记（mask tokens）**添加到编码后的token列表中，以表示那些被移除的块。
   - 然后，使用初始的随机打乱顺序的逆操作（unshuffle），将这些token恢复到原来的位置，确保每个token的位置与它们的目标一致。

5. **解码器处理**：
   - 这个恢复后的完整token列表（包含位置嵌入）被送入解码器，解码器用于重建图像。

6. **实现的简化**：
   - 作者指出，这一过程不需要使用任何专门的稀疏操作，因为shuffle和unshuffle的操作很快且没有显著的额外开销。这种实现方法简化了整个处理过程，使得模型在预训练中更加高效。

**总结**：通过这种实现方式，模型能够高效地随机掩码并处理图像块，避免了稀疏矩阵操作的复杂性，同时保持了操作的速度和效率。
```
